{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55be2455-9f7e-4fa1-9e6a-25a38cc9259c",
   "metadata": {},
   "source": [
    "# Import Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0783890-e33c-4970-8bd2-0a0a0b26c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59eca47-b76c-4766-b4b7-8fed30e0eb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.366039</td>\n",
       "      <td>0.476383</td>\n",
       "      <td>9279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.970104</td>\n",
       "      <td>0.268790</td>\n",
       "      <td>22563.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.786730</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>9995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.441181</td>\n",
       "      <td>0.414536</td>\n",
       "      <td>11259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.863872</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>15750.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2    price\n",
       "0 -0.366039  0.476383   9279.0\n",
       "1  4.970104  0.268790  22563.0\n",
       "2 -0.786730  0.023457   9995.0\n",
       "3 -0.441181  0.414536  11259.0\n",
       "4  1.863872  0.750249  15750.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load \n",
    "df = pd.read_csv('../data/train_v6.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d364064-b16a-4575-b6e5-627de93ab5e8",
   "metadata": {},
   "source": [
    "# Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4635e324-6e2f-4559-af8a-4db76243cd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample dataset\n",
    "features = df.drop(columns=['price'])\n",
    "target = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d897c6-b9a7-40f8-b4eb-aaa9bf33dd86",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7940b2f-94c9-470d-95d5-9c4b83a3ecef",
   "metadata": {},
   "source": [
    "Regression is a supervised learning task used for predicting a continuous numeric value. There are several regression models available in Python. The choice of the best regression model depends on your specific dataset and problem. Here are some commonly used regression models with Python examples:\n",
    "1. <b>Linear Regression:</b><br>\n",
    "    Linear regression is a simple and widely used model that assumes a linear relationship between the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5302a14-7c40-4ab2-804d-adc67a3e6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c854fb-567f-47bb-b170-f4021ffd7b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f156ce8-4c9e-4a0f-961a-a647b6951865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baff4270-28c6-4cce-9044-71d2975ae918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62305b61-5d78-46e4-bc06-560159b8a925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2647.0125175088956\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3dc9a8-fdf6-4cc7-9ce1-432dade7d263",
   "metadata": {},
   "source": [
    "2. <b>Ridge Regression:</b><br>\n",
    "    Ridge regression is a linear regression variant that adds L2 regularization to the cost function. It's useful for handling multicollinearity and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f4fb9ce-2fd0-4634-be48-e3611c8ff69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2647.094775828543\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Fit a Ridge regression model\n",
    "model = Ridge(alpha=1.0)  # You can adjust the alpha (regularization strength)\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac825d-7e92-45f0-bfb5-e104c7260f2e",
   "metadata": {},
   "source": [
    "3. <b>Lasso Regression:</b><br>\n",
    "    Lasso regression is another linear regression variant that adds L1 regularization to the cost function. It helps with feature selection and can set some feature coefficients to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf89148c-2dce-44aa-a44a-1343988d0ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 2647.0125175406306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit a Lasso regression model\n",
    "model = Lasso(alpha=0.01)  # You can adjust the alpha (regularization strength)\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7385e0-891a-48f8-856d-d114866c0c24",
   "metadata": {},
   "source": [
    "4. <b>Decision Tree Regression:</b><br>\n",
    "    Decision tree regression can capture complex non-linear relationships between features and the target variable. It partitions the feature space into regions and predicts the average of the target values in each region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc37896d-b5fd-45a9-9dd6-b6b76be883a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 318.60875452745876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Fit a Decision Tree regression model\n",
    "model = DecisionTreeRegressor(max_depth=75)  # You can adjust the max depth\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d4993-ee37-4e53-8a46-4e9d31d0d7fd",
   "metadata": {},
   "source": [
    "5. <b>Random Forest Regression:</b><br>\n",
    "    Random Forest is an ensemble method that combines multiple decision trees to improve predictive accuracy and reduce overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aef63b73-45eb-4d4d-bcb0-9c9150e82117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 979.0146634212703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Fit a Random Forest regression model\n",
    "model = RandomForestRegressor(n_estimators=100)  # You can adjust the number of trees\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a37fa-a756-4da7-a660-7c422ca08ab1",
   "metadata": {},
   "source": [
    "6. <b>Support Vector Regression (SVR):</b><br>\n",
    "    Support Vector Regression is based on support vector machines and is suitable for both linear and non-linear regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cc3a1f06-2530-4ade-9984-eaf02a78e330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 6390.212685503681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Fit a Support Vector Regression model\n",
    "model = SVR(kernel='linear', C=1.0)  # You can adjust the kernel and C parameter\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83a80d-6d21-4b47-9a34-4c679c564b45",
   "metadata": {},
   "source": [
    "Certainly! Here are some more regression models that you can consider for your machine learning tasks:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ab2b8-6092-4944-976f-309547bb31a3",
   "metadata": {},
   "source": [
    "1. <b style=\"color: #B15EFF;\">Gradient Boosting Regressor:</b><br>\n",
    "    Gradient Boosting is an ensemble method that builds an additive model in a forward stage-wise manner. It can handle complex non-linear relationships and is often a top performer in regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa7329c8-e286-483e-8785-caf27617a5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 370.45547330504996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Fit a Gradient Boosting regression model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1)  # Adjust hyperparameters\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67431eaf-e14b-45ad-b2c3-53b1b64ad293",
   "metadata": {},
   "source": [
    "2. <b style=\"color: #0C356A;\">AdaBoost Regressor:</b><br>\n",
    "    AdaBoost is another ensemble method that combines multiple weak learners to create a strong learner. It's particularly effective for regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "220376a6-d3dd-436a-a88b-c82b3dc92876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 1056.0473967940486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Fit an AdaBoost regression model\n",
    "model = AdaBoostRegressor(n_estimators=100, learning_rate=0.1)  # Adjust hyperparameters\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef481bef-a668-4ab1-9977-8751eff6f0e1",
   "metadata": {},
   "source": [
    "3. <b style=\"color: #DA0C81;\">XGBoost Regressor:</b><br>\n",
    "    XGBoost is a highly optimized gradient boosting library that often outperforms other models in regression tasks. It offers excellent predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1d8cb-8f3e-4970-879e-c7b7297e20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Fit an XGBoost regression model\n",
    "model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1)  # Adjust hyperparameters\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f46f9a-ed25-4574-a9ff-d536ea81ec0e",
   "metadata": {},
   "source": [
    "4. <b style=\"color: #CD5C08;\">K-Nearest Neighbors (KNN) Regressor:</b><br>\n",
    "    KNN is a non-parametric method that makes predictions based on the average of the K nearest data points. It's simple and flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f230555-076d-4638-af99-a5765f4887ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create a sample dataset\n",
    "# (same as in the linear regression example)\n",
    "\n",
    "# Fit a KNN regression model\n",
    "model = KNeighborsRegressor(n_neighbors=5)  # Adjust the number of neighbors (K)\n",
    "model.fit(features, target)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(features)\n",
    "\n",
    "# Calculate and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(target, y_pred))\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
